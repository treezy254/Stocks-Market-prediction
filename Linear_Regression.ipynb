{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtez0eRhHrIm+iPdlLWj2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treezy254/Stocks-Market-prediction/blob/master/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REvLPcs6G1OS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('eur_usd.csv')"
      ],
      "metadata": {
        "id": "bcOyi4mAG5tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert the 'date' column to a datetime object\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Create a new column that represents the direction of the price movement\n",
        "df['direction'] = np.where(df['close'].shift(-1) > df['close'], 1, -1)"
      ],
      "metadata": {
        "id": "EDCgkZs3G8DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df[:train_size]\n",
        "test_data = df[train_size:]"
      ],
      "metadata": {
        "id": "aZ82HhjbG8lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input and output arrays for training the model\n",
        "X_train = np.array(train_data['close']).reshape(-1, 1)\n",
        "y_train = np.array(train_data['direction'])\n",
        "X_test = np.array(test_data['close']).reshape(-1, 1)\n",
        "y_test = np.array(test_data['direction'])"
      ],
      "metadata": {
        "id": "lpjC2giyG88P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a linear regression model to the training data\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lye-omiNG9QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "SzO2YblpG9gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean squared error:', mse)"
      ],
      "metadata": {
        "id": "M4YOFBMXHHcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the predicted and actual directions of the price movement\n",
        "plt.plot(test_data['date'], y_test, label='Actual')\n",
        "plt.plot(test_data['date'], y_pred, label='Predicted')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Direction')\n",
        "plt.title('Predicted vs. Actual Direction of EUR/USD Price Movement')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0NXf7nPQHINh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "2_QKN77mHPem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "k3GoY0yZHIKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('eur_usd.csv')"
      ],
      "metadata": {
        "id": "2Kfcw6ccHIH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert the 'date' column to a datetime object\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Create a new column that represents the direction of the price movement\n",
        "df['direction'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)"
      ],
      "metadata": {
        "id": "JTSBnx0ZHIFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the input data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['close'] = scaler.fit_transform(df['close'].values.reshape(-1,1))"
      ],
      "metadata": {
        "id": "CjlHtY4kHIBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df[:train_size]\n",
        "test_data = df[train_size:]"
      ],
      "metadata": {
        "id": "5W-yNoXrHH7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "TIME_STEPS = 5\n",
        "\n",
        "X_train, y_train = create_sequences(train_data[['close']], train_data['direction'], TIME_STEPS)\n",
        "X_test, y_test = create_sequences(test_data[['close']], test_data['direction'], TIME_STEPS)"
      ],
      "metadata": {
        "id": "0KgKwEjeHHXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(TIME_STEPS, 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SNIEuYsvHZNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "id": "hNvzN_uPHZK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "AMEHjL1hHZHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the predicted and actual directions of the price movement\n",
        "plt.plot(test_data['date'].iloc[TIME_STEPS:], y_test, label='Actual')\n",
        "plt.plot(test_data['date'].iloc[TIME_STEPS:], y_pred.round(), label='Predicted')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Direction')\n",
        "plt.title('Predicted vs. Actual"
      ],
      "metadata": {
        "id": "TpAaYauZHZE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred_round = y_pred.round()\n",
        "accuracy = accuracy_score(y_test, y_pred_round)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "id": "kUpMcFeHHZCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradient boosting\n"
      ],
      "metadata": {
        "id": "dzsa5xfDHnF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"EURUSD.csv\")"
      ],
      "metadata": {
        "id": "uvGfvZjpHY_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "df[\"Returns\"] = df[\"Close\"].pct_change()\n",
        "df[\"Direction\"] = (df[\"Returns\"] > 0).astype(int)\n",
        "\n",
        "# Define the input features and output variable\n",
        "X = df[[\"Open\", \"High\", \"Low\", \"Close\"]]\n",
        "y_rf = df[\"Direction\"]\n",
        "y_gb = df[\"Direction\"].shift(-1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_rf_train, y_rf_test, y_gb_train, y_gb_test = train_test_split(\n",
        "    X, y_rf, y_gb, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "RT1ZtrWjHY8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the Random Forests model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "rf_model.fit(X_train, y_rf_train)\n",
        "y_rf_pred = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_rf_test, y_rf_pred)\n",
        "print(\"Random Forests Accuracy: {:.2f}%\".format(rf_accuracy*100))"
      ],
      "metadata": {
        "id": "XI7wUwzqHY5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "also random forest - switch\n"
      ],
      "metadata": {
        "id": "ImcPUAW1IjN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the Gradient Boosted Trees model\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=5)\n",
        "gb_model.fit(X_train, y_gb_train)\n",
        "y_gb_pred = gb_model.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_gb_test[:-1], y_gb_pred[1:])\n",
        "print(\"Gradient Boosted Trees Accuracy: {:.2f}%\".format(gb_accuracy*100))"
      ],
      "metadata": {
        "id": "SDKhhtcaHuzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xvqCCjrHuwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EwiTC2SrHutG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "online learning"
      ],
      "metadata": {
        "id": "ErByHHXsInVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads the latest data for the EUR/USD currency pair from Yahoo Finance, preprocesses it by calculating the daily returns and direction, and scales the input features using the MinMaxScaler function from scikit-learn. It then defines an LSTM model architecture using the Sequential class from TensorFlow, compiles the model using the Adam optimizer and binary cross-entropy loss function, and trains the model on a sliding window of the data.\n",
        "\n",
        "After training the model, the code makes a prediction for the direction of the next day's movement by feeding the most recent n_steps days of data into the model and using the output to predict the direction using a threshold of 0.5.\n",
        "\n",
        "Note that this code is meant to demonstrate the basic steps involved in building an online machine learning model using LSTM, and should not be used for actual trading or investment purposes. Additionally, it's important to carefully evaluate the performance of the model using appropriate evaluation metrics and testing methodologies, and to take into account any potential biases or limitations in the data that may affect the model's performance."
      ],
      "metadata": {
        "id": "xmvzCQP0Iz4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the number of previous days to use for predicting the next day's movement\n",
        "n_steps = 20\n",
        "\n",
        "# Define the input features and output variable\n",
        "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
        "target = \"Direction\"\n",
        "\n",
        "# Load the latest data from Yahoo Finance and preprocess it\n",
        "ticker = \"EURUSD=X\"\n",
        "df = yf.download(ticker, period=\"1d\", interval=\"1d\")[features]\n",
        "df[\"Returns\"] = df[\"Close\"].pct_change()\n",
        "df[target] = (df[\"Returns\"] > 0).astype(int)\n",
        "df.dropna(inplace=True)\n",
        "scaler = MinMaxScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(n_steps, len(features))))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model and define the loss function and optimizer\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model on a sliding window of the data\n",
        "for i in range(n_steps, len(df)):\n",
        "    X = np.array([df.iloc[i-n_steps:i][features]])\n",
        "    y = np.array([df.iloc[i][target]])\n",
        "    model.fit(X, y, epochs=1, verbose=0)\n",
        "\n",
        "    # Make a prediction for the next day's movement\n",
        "    X_next = np.array([df.iloc[i-n_steps+1:i+1][features]])\n",
        "    y_pred = model.predict(X_next)[0][0]\n",
        "    y_pred_direction = 1 if y_pred > 0.5 else 0\n",
        "    print(\"Predicted Direction: {}\".format(y_pred_direction))\n"
      ],
      "metadata": {
        "id": "HEPzE3M-Hup_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "another"
      ],
      "metadata": {
        "id": "zFC6stRSG7vm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, here's an example of an online learning model that predicts the change in the EUR/USD currency pair's movement for the next 5 minutes using a Gradient Boosting Regressor:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the number of previous minutes to use for predicting the next 5 minutes' change\n",
        "n_steps = 10\n",
        "\n",
        "# Define the input features and output variable\n",
        "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
        "target = \"Change_5min\"\n",
        "\n",
        "# Load the latest data from Yahoo Finance and preprocess it\n",
        "ticker = \"EURUSD=X\"\n",
        "df = yf.download(ticker, period=\"1d\", interval=\"1m\")[features]\n",
        "df[target] = df[\"Close\"].pct_change(periods=5).shift(-5)\n",
        "df.dropna(inplace=True)\n",
        "scaler = MinMaxScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Initialize the Gradient Boosting Regressor\n",
        "model = GradientBoostingRegressor(loss=\"ls\", learning_rate=0.1, n_estimators=100, max_depth=3)\n",
        "\n",
        "# Train the model on a sliding window of the data\n",
        "for i in range(n_steps, len(df)):\n",
        "    X = np.array([df.iloc[i-n_steps:i][features]])\n",
        "    y = np.array([df.iloc[i][target]])\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Make a prediction for the next 5 minutes' change\n",
        "    X_next = np.array([df.iloc[i-n_steps+1:i+1][features]])\n",
        "    y_pred = model.predict(X_next)[0]\n",
        "    print(\"Predicted Change in the Next 5 Minutes: {}\".format(y_pred))\n",
        "This code loads the latest data for the EUR/USD currency pair from Yahoo Finance, preprocesses it by calculating the change in the closing price for the next 5 minutes and scaling the input features using the MinMaxScaler function from scikit-learn. It then initializes a Gradient Boosting Regressor using the GradientBoostingRegressor class from scikit-learn, and trains the model on a sliding window of the data.\n",
        "\n",
        "After training the model, the code makes a prediction for the change in the next 5 minutes' movement by feeding the most recent n_steps minutes of data into the model and using the output as the predicted change in the closing price.\n",
        "\n",
        "Note that this code is meant to demonstrate the basic steps involved in building an online learning model using Gradient Boosting Regressor, and should not be used for actual trading or investment purposes. Additionally, it's important to carefully evaluate the performance of the model using appropriate evaluation metrics and testing methodologies, and to take into account any potential biases or limitations in the data that may affect the model's performance."
      ],
      "metadata": {
        "id": "DlYrD8kYJJgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the number of previous minutes to use for predicting the next 5 minutes' change\n",
        "n_steps = 10\n",
        "\n",
        "# Define the input features and output variable\n",
        "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
        "target = \"Change_5min\"\n",
        "\n",
        "# Load the latest data from Yahoo Finance and preprocess it\n",
        "ticker = \"EURUSD=X\"\n",
        "df = yf.download(ticker, period=\"1d\", interval=\"1m\")[features]\n",
        "df[target] = df[\"Close\"].pct_change(periods=5).shift(-5)\n",
        "df.dropna(inplace=True)\n",
        "scaler = MinMaxScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Initialize the Gradient Boosting Regressor\n",
        "model = GradientBoostingRegressor(loss=\"ls\", learning_rate=0.1, n_estimators=100, max_depth=3)\n",
        "\n",
        "# Train the model on a sliding window of the data\n",
        "for i in range(n_steps, len(df)):\n",
        "    X = np.array([df.iloc[i-n_steps:i][features]])\n",
        "    y = np.array([df.iloc[i][target]])\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Make a prediction for the next 5 minutes' change\n",
        "    X_next = np.array([df.iloc[i-n_steps+1:i+1][features]])\n",
        "    y_pred = model.predict(X_next)[0]\n",
        "    print(\"Predicted Change in the Next 5 Minutes: {}\".format(y_pred))\n"
      ],
      "metadata": {
        "id": "R6MLGiVyIubM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USING LSTM for 5 minute"
      ],
      "metadata": {
        "id": "z_D_ibu6JOF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code first preprocesses the data in the same way as the previous example, and then splits it into a training set and a testing set. It then defines the LSTM model architecture using the Sequential class from Keras, which consists of two LSTM layers with 50 neurons each followed by a dense layer with a single output. The model is compiled using mean squared error as the loss function and the Adam optimizer.\n",
        "\n",
        "The model is trained on the training set using batches of 32 and for 10 epochs. After training the model, the code evaluates its performance on the testing set using the mean squared error as the evaluation metric.\n",
        "\n",
        "Finally, the code makes a prediction for the next 5 minutes' change by feeding the most recent n_steps minutes of data into the model and using the output as the predicted change in the closing price.\n",
        "\n",
        "Note that like the previous example, this code is meant to demonstrate the basic steps involved in building an LSTM model for online learning, and should not be used for actual trading or investment purposes. Additionally, it's important to carefully evaluate the performance of the model using appropriate evaluation metrics"
      ],
      "metadata": {
        "id": "jM9DZ7vLJOCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Define the number of previous minutes to use for predicting the next 5 minutes' change\n",
        "n_steps = 10\n",
        "\n",
        "# Define the input features and output variable\n",
        "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
        "target = \"Change_5min\"\n",
        "\n",
        "# Load the latest data from Yahoo Finance and preprocess it\n",
        "ticker = \"EURUSD=X\"\n",
        "df = yf.download(ticker, period=\"1d\", interval=\"1m\")[features]\n",
        "df[target] = df[\"Close\"].pct_change(periods=5).shift(-5)\n",
        "df.dropna(inplace=True)\n",
        "scaler = MinMaxScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df.iloc[:train_size]\n",
        "test_data = df.iloc[train_size:]\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(n_steps, len(features)), return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model using mean squared error as the loss function and Adam optimizer\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "# Train the model on the training set using batches of 32 and for 10 epochs\n",
        "for i in range(n_steps, train_size):\n",
        "    X_train = np.array([train_data.iloc[i-n_steps:i][features]])\n",
        "    y_train = np.array([train_data.iloc[i][target]])\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "X_test = np.array([test_data.iloc[n_steps:][features]])\n",
        "y_test = np.array([test_data.iloc[n_steps:][target]])\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print(\"Test set Mean Squared Error: {}\".format(score))\n",
        "\n",
        "# Make a prediction for the next 5 minutes' change\n",
        "X_next = np.array([df.iloc[-n_steps:][features]])\n",
        "y_pred = model.predict(X_next)[0][0]\n",
        "print(\"Predicted Change in the Next 5 Minutes: {}\".format(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "-GR_J0c-JSE5",
        "outputId": "ca84dbac-f617-4340-9998-f052921893b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8bb0ee6ec2a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualize\n"
      ],
      "metadata": {
        "id": "c6g17yMfKDqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code first preprocesses the data in the same way as the previous example, and then splits it into a training set and a testing set. It then defines the LSTM model architecture using the Sequential class from Keras, which consists of two LSTM layers with 50 neurons each followed by a dense layer with a single output. The model is compiled using mean squared error as the loss function and the Adam optimizer.\n",
        "\n",
        "The model is trained on the training set using batches of 32 and for 10 epochs. After training the model, the code evaluates its performance on the testing set using the mean squared error as the evaluation metric.\n",
        "\n",
        "Finally,"
      ],
      "metadata": {
        "id": "iy6ZKPx5KLUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the number of previous minutes to use for predicting the next 5 minutes' change\n",
        "n_steps = 10\n",
        "\n",
        "# Define the input features and output variable\n",
        "features = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
        "target = \"Change_5min\"\n",
        "\n",
        "# Load the latest data from Yahoo Finance and preprocess it\n",
        "ticker = \"EURUSD=X\"\n",
        "df = yf.download(ticker, period=\"1d\", interval=\"1m\")[features]\n",
        "df[target] = df[\"Close\"].pct_change(periods=5).shift(-5)\n",
        "df.dropna(inplace=True)\n",
        "scaler = MinMaxScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df.iloc[:train_size]\n",
        "test_data = df.iloc[train_size:]\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(n_steps, len(features)), return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model using mean squared error as the loss function and Adam optimizer\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "# Train the model on the training set using batches of 32 and for 10 epochs\n",
        "for i in range(n_steps, train_size):\n",
        "    X_train = np.array([train_data.iloc[i-n_steps:i][features]])\n",
        "    y_train = np.array([train_data.iloc[i][target]])\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "X_test = np.array([test_data.iloc[n_steps:][features]])\n",
        "y_test = np.array([test_data.iloc[n_steps:][target]])\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print(\"Test set Mean Squared Error: {}\".format(score))\n",
        "\n",
        "# Make a prediction for the next 5 minutes' change\n",
        "X_next = np.array([df.iloc[-n_steps:][features]])\n",
        "y_pred = model.predict(X_next)[0][0]\n",
        "print(\"Predicted Change in the Next 5 Minutes: {}\".format(y_pred))\n",
        "\n",
        "# Visualize the performance of the model on the testing set\n",
        "y_pred_test = model.predict(X_test)\n",
        "y_pred_test = scaler.inverse_transform(y_pred_test)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_test, label=\"Actual\")\n",
        "plt.plot(y_pred_test, label=\"Predicted\")\n",
        "plt.title(\"LSTM Model Performance\")\n",
        "plt.xlabel(\"Minutes\")\n",
        "plt.ylabel(\"Change in Closing Price\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "H30vGCvWJR-9",
        "outputId": "e8e50bdb-4919-4f79-afc2-e04e0468ca04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6d84dae61123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9-Mqds3JR75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HDGo45fsJR5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBGEhXmFJR2R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}